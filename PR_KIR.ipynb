{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10337, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"LanguageDetection.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from Language Detection.csv\n",
    "file_path = 'LanguageDetection.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove null values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "output_path = 'cleaned_data.csv'\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10337, 2)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 195.2 kB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "     -------------------------------------- 78.3/78.3 kB 155.6 kB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.10.3-cp310-cp310-win_amd64.whl (269 kB)\n",
      "     ------------------------------------ 269.6/269.6 kB 448.6 kB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     ------------------------------------ 302.2/302.2 kB 236.4 kB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     -------------------------------------- 97.9/97.9 kB 122.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\kiranmai\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1 regex-2023.10.3 tqdm-4.66.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Read the data from LanguageDataset.csv\n",
    "file_path = 'LanguageDetection.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the column names are as expected ('Text' and 'Language')\n",
    "df.columns = df.columns.str.strip()  # Remove leading/trailing whitespaces\n",
    "\n",
    "# Make sure to replace 'Text' with the actual column name in your dataset\n",
    "text_column_name = 'Text'\n",
    "\n",
    "# Function for text cleaning and preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters, numbers, and other non-text elements\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing to the specified column\n",
    "df['Text'] = df[text_column_name].apply(preprocess_text).apply(word_tokenize)\n",
    "\n",
    "# Create a new DataFrame with only the 'tokens' and 'Language' columns\n",
    "df_output = df[['Text', 'Language']]\n",
    "# df_output.rename('Text')\n",
    "# Save the preprocessed data to a new CSV file\n",
    "output_path = 'preprocessed.csv'\n",
    "df_output.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Preprocessed data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-win_amd64.whl (9.3 MB)\n",
      "     ---------------------------------------- 9.3/9.3 MB 446.6 kB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.11.4-cp310-cp310-win_amd64.whl (44.1 MB)\n",
      "     -------------------------------------- 44.1/44.1 MB 457.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.2 scipy-1.11.4 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words (BoW) representation:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "TF-IDF representation:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the preprocessed data from 'preprocessed.csv'\n",
    "preprocessed_path = 'preprocessed.csv'\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    df['Text'], df['Language'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Bag-of-Words (BoW) representation\n",
    "bow_vectorizer = CountVectorizer()\n",
    "train_bow = bow_vectorizer.fit_transform(train_data)\n",
    "test_bow = bow_vectorizer.transform(test_data)\n",
    "\n",
    "# TF-IDF representation\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(train_data)\n",
    "test_tfidf = tfidf_vectorizer.transform(test_data)\n",
    "\n",
    "# Display the feature matrices\n",
    "print(\"Bag-of-Words (BoW) representation:\")\n",
    "print(train_bow.toarray())\n",
    "\n",
    "print(\"\\nTF-IDF representation:\")\n",
    "print(train_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.02      0.04       106\n",
      "      Danish       0.94      0.88      0.91        73\n",
      "       Dutch       1.00      0.93      0.96       111\n",
      "     English       0.97      0.97      0.97       291\n",
      "      French       0.99      0.93      0.96       219\n",
      "      German       0.99      0.92      0.96        93\n",
      "       Greek       0.25      0.01      0.03        68\n",
      "       Hindi       0.00      0.00      0.00        10\n",
      "     Italian       1.00      0.92      0.96       145\n",
      "     Kannada       0.00      0.00      0.00        66\n",
      "   Malayalam       0.00      0.00      0.00       121\n",
      "  Portugeese       0.99      0.92      0.96       144\n",
      "     Russian       0.20      0.99      0.33       136\n",
      "     Spanish       0.97      0.93      0.95       160\n",
      "    Sweedish       0.98      0.88      0.93       133\n",
      "       Tamil       0.00      0.00      0.00        87\n",
      "     Turkish       1.00      0.80      0.89       105\n",
      "\n",
      "    accuracy                           0.72      2068\n",
      "   macro avg       0.66      0.60      0.58      2068\n",
      "weighted avg       0.77      0.72      0.70      2068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read the preprocessed data from 'preprocessed.csv'\n",
    "preprocessed_path = 'preprocessed.csv'\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    df['Text'], df['Language'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TF-IDF representation\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(train_data)\n",
    "test_tfidf = tfidf_vectorizer.transform(test_data)\n",
    "\n",
    "# Initialize and train the Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear')  # You can experiment with different kernels (linear, rbf, etc.)\n",
    "svm_model.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = svm_model.predict(test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "classification_report_result = classification_report(test_labels, predictions)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before hyperparameter tuning: 0.72\n",
      "\n",
      "Classification Report before hyperparameter tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.02      0.04       106\n",
      "      Danish       0.94      0.88      0.91        73\n",
      "       Dutch       1.00      0.93      0.96       111\n",
      "     English       0.97      0.97      0.97       291\n",
      "      French       0.99      0.93      0.96       219\n",
      "      German       0.99      0.92      0.96        93\n",
      "       Greek       0.25      0.01      0.03        68\n",
      "       Hindi       0.00      0.00      0.00        10\n",
      "     Italian       1.00      0.92      0.96       145\n",
      "     Kannada       0.00      0.00      0.00        66\n",
      "   Malayalam       0.00      0.00      0.00       121\n",
      "  Portugeese       0.99      0.92      0.96       144\n",
      "     Russian       0.20      0.99      0.33       136\n",
      "     Spanish       0.97      0.93      0.95       160\n",
      "    Sweedish       0.98      0.88      0.93       133\n",
      "       Tamil       0.00      0.00      0.00        87\n",
      "     Turkish       1.00      0.80      0.89       105\n",
      "\n",
      "    accuracy                           0.72      2068\n",
      "   macro avg       0.66      0.60      0.58      2068\n",
      "weighted avg       0.77      0.72      0.70      2068\n",
      "\n",
      "\n",
      "Best Hyperparameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy after hyperparameter tuning: 0.75\n",
      "\n",
      "Classification Report after hyperparameter tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.02      0.04       106\n",
      "      Danish       0.96      0.89      0.92        73\n",
      "       Dutch       1.00      0.92      0.96       111\n",
      "     English       0.86      0.99      0.92       291\n",
      "      French       0.97      0.99      0.98       219\n",
      "      German       1.00      0.92      0.96        93\n",
      "       Greek       0.25      0.01      0.03        68\n",
      "       Hindi       0.00      0.00      0.00        10\n",
      "     Italian       1.00      0.95      0.98       145\n",
      "     Kannada       0.33      0.02      0.03        66\n",
      "   Malayalam       0.00      0.00      0.00       121\n",
      "  Portugeese       0.99      0.95      0.97       144\n",
      "     Russian       0.22      0.91      0.35       136\n",
      "     Spanish       0.93      0.97      0.95       160\n",
      "    Sweedish       0.97      0.95      0.96       133\n",
      "       Tamil       0.00      0.00      0.00        87\n",
      "     Turkish       0.98      0.95      0.97       105\n",
      "\n",
      "    accuracy                           0.75      2068\n",
      "   macro avg       0.67      0.62      0.59      2068\n",
      "weighted avg       0.76      0.75      0.71      2068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read the preprocessed data from 'preprocessed.csv'\n",
    "preprocessed_path = 'preprocessed.csv'\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    df['Text'], df['Language'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TF-IDF representation\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(train_data)\n",
    "test_tfidf = tfidf_vectorizer.transform(test_data)\n",
    "\n",
    "# Initialize and train the Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear')  # You can experiment with different kernels (linear, rbf, etc.)\n",
    "svm_model.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = svm_model.predict(test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "classification_report_result = classification_report(test_labels, predictions)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"Accuracy before hyperparameter tuning: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report before hyperparameter tuning:\")\n",
    "print(classification_report_result)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto'], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Re-train the model with the best hyperparameters\n",
    "best_svm_model = SVC(**best_params)\n",
    "best_svm_model.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predictions on the test set using the tuned model\n",
    "tuned_predictions = best_svm_model.predict(test_tfidf)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "tuned_accuracy = accuracy_score(test_labels, tuned_predictions)\n",
    "tuned_classification_report_result = classification_report(test_labels, tuned_predictions)\n",
    "\n",
    "# Display evaluation metrics after hyperparameter tuning\n",
    "print(f\"\\nBest Hyperparameters: {best_params}\")\n",
    "print(f\"Accuracy after hyperparameter tuning: {tuned_accuracy:.2f}\")\n",
    "print(\"\\nClassification Report after hyperparameter tuning:\")\n",
    "print(tuned_classification_report_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before hyperparameter tuning: 0.72\n",
      "\n",
      "Classification Report before hyperparameter tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.02      0.04       106\n",
      "      Danish       0.94      0.88      0.91        73\n",
      "       Dutch       1.00      0.93      0.96       111\n",
      "     English       0.97      0.97      0.97       291\n",
      "      French       0.99      0.93      0.96       219\n",
      "      German       0.99      0.92      0.96        93\n",
      "       Greek       0.25      0.01      0.03        68\n",
      "       Hindi       0.00      0.00      0.00        10\n",
      "     Italian       1.00      0.92      0.96       145\n",
      "     Kannada       0.00      0.00      0.00        66\n",
      "   Malayalam       0.00      0.00      0.00       121\n",
      "  Portugeese       0.99      0.92      0.96       144\n",
      "     Russian       0.20      0.99      0.33       136\n",
      "     Spanish       0.97      0.93      0.95       160\n",
      "    Sweedish       0.98      0.88      0.93       133\n",
      "       Tamil       0.00      0.00      0.00        87\n",
      "     Turkish       1.00      0.80      0.89       105\n",
      "\n",
      "    accuracy                           0.72      2068\n",
      "   macro avg       0.66      0.60      0.58      2068\n",
      "weighted avg       0.77      0.72      0.70      2068\n",
      "\n",
      "\n",
      "Best Hyperparameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy after hyperparameter tuning: 0.75\n",
      "\n",
      "Classification Report after hyperparameter tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.02      0.04       106\n",
      "      Danish       0.96      0.89      0.92        73\n",
      "       Dutch       1.00      0.92      0.96       111\n",
      "     English       0.86      0.99      0.92       291\n",
      "      French       0.97      0.99      0.98       219\n",
      "      German       1.00      0.92      0.96        93\n",
      "       Greek       0.25      0.01      0.03        68\n",
      "       Hindi       0.00      0.00      0.00        10\n",
      "     Italian       1.00      0.95      0.98       145\n",
      "     Kannada       0.33      0.02      0.03        66\n",
      "   Malayalam       0.00      0.00      0.00       121\n",
      "  Portugeese       0.99      0.95      0.97       144\n",
      "     Russian       0.22      0.91      0.35       136\n",
      "     Spanish       0.93      0.97      0.95       160\n",
      "    Sweedish       0.97      0.95      0.96       133\n",
      "       Tamil       0.00      0.00      0.00        87\n",
      "     Turkish       0.98      0.95      0.97       105\n",
      "\n",
      "    accuracy                           0.75      2068\n",
      "   macro avg       0.67      0.62      0.59      2068\n",
      "weighted avg       0.76      0.75      0.71      2068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display evaluation metrics before hyperparameter tuning\n",
    "print(f\"Accuracy before hyperparameter tuning: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report before hyperparameter tuning:\")\n",
    "print(classification_report_result)\n",
    "\n",
    "# Display evaluation metrics after hyperparameter tuning\n",
    "print(f\"\\nBest Hyperparameters: {best_params}\")\n",
    "print(f\"Accuracy after hyperparameter tuning: {tuned_accuracy:.2f}\")\n",
    "print(\"\\nClassification Report after hyperparameter tuning:\")\n",
    "print(tuned_classification_report_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
      "     -------------------------------------- 99.7/99.7 kB 143.2 kB/s eta 0:00:00\n",
      "Collecting Werkzeug>=3.0.0\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "     ------------------------------------- 226.7/226.7 kB 91.1 kB/s eta 0:00:00\n",
      "Collecting blinker>=1.6.2\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting Jinja2>=3.1.2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask) (8.1.7)\n",
      "Collecting itsdangerous>=2.1.2\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kiranmai\\appdata\\roaming\\python\\python310\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.3-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Installing collected packages: MarkupSafe, itsdangerous, blinker, Werkzeug, Jinja2, flask\n",
      "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.3 Werkzeug-3.0.1 blinker-1.7.0 flask-3.0.0 itsdangerous-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIRANMAI\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the preprocessed data\n",
    "preprocessed_path = 'preprocessed.csv'\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "\n",
    "# TF-IDF representation\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X, df['Language'])\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "model_path = 'language_detection_model.joblib'\n",
    "vectorizer_path = 'tfidf_vectorizer.joblib'\n",
    "joblib.dump(svm_model, model_path)\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Get the input text from the request\n",
    "        data = request.get_json()\n",
    "        text = data['text']\n",
    "\n",
    "        # Preprocess and vectorize the input text\n",
    "        text = text.lower()\n",
    "        text_tfidf = tfidf_vectorizer.transform([text])\n",
    "\n",
    "        # Predict the language\n",
    "        prediction = svm_model.predict(text_tfidf)[0]\n",
    "\n",
    "        # Return the prediction\n",
    "        return jsonify({'language': prediction})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n",
      "Model Accuracy: 0.74\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KIRANMAI\\OneDrive\\Documents\\PR_PROJECT\\PR.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m new_data \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Monitor model performance on the new data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m accuracy \u001b[39m=\u001b[39m monitor_model_performance(svm_model, tfidf_vectorizer, new_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# # Schedule the monitoring every 24 hours\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# time.sleep()  # Sleep for 24 hours\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\KIRANMAI\\OneDrive\\Documents\\PR_PROJECT\\PR.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m text_tfidf \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mtransform(data[\u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Predict the language\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(text_tfidf)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KIRANMAI/OneDrive/Documents/PR_PROJECT/PR.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m accuracy \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(data[\u001b[39m'\u001b[39m\u001b[39mLanguage\u001b[39m\u001b[39m'\u001b[39m], predictions)\n",
      "File \u001b[1;32mc:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:818\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    816\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    817\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    819\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[1;32mc:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    431\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    432\u001b[0m predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[1;32m--> 433\u001b[0m \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32mc:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:479\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    475\u001b[0m kernel_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_kernels\u001b[39m.\u001b[39mindex(kernel)\n\u001b[0;32m    477\u001b[0m C \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m  \u001b[39m# C is not useful here\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m \u001b[39mreturn\u001b[39;00m libsvm_sparse\u001b[39m.\u001b[39;49mlibsvm_sparse_predict(\n\u001b[0;32m    480\u001b[0m     X\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    481\u001b[0m     X\u001b[39m.\u001b[39;49mindices,\n\u001b[0;32m    482\u001b[0m     X\u001b[39m.\u001b[39;49mindptr,\n\u001b[0;32m    483\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    484\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_\u001b[39m.\u001b[39;49mindices,\n\u001b[0;32m    485\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_\u001b[39m.\u001b[39;49mindptr,\n\u001b[0;32m    486\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dual_coef_\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    487\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intercept_,\n\u001b[0;32m    488\u001b[0m     LIBSVM_IMPL\u001b[39m.\u001b[39;49mindex(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_impl),\n\u001b[0;32m    489\u001b[0m     kernel_type,\n\u001b[0;32m    490\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    491\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    492\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    494\u001b[0m     C,\n\u001b[0;32m    495\u001b[0m     \u001b[39m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    496\u001b[0m     \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_class_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[0;32m    497\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    498\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    499\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    500\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    501\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_support,\n\u001b[0;32m    502\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probA,\n\u001b[0;32m    503\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probB,\n\u001b[0;32m    504\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Function to monitor model performance\n",
    "def monitor_model_performance(model, vectorizer, data):\n",
    "    # Preprocess and vectorize the data\n",
    "    text_tfidf = vectorizer.transform(data['Text'])\n",
    "\n",
    "    # Predict the language\n",
    "    predictions = model.predict(text_tfidf)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = metrics.accuracy_score(data['Language'], predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Load the preprocessed data (or replace with your data loading logic)\n",
    "preprocessed_path = 'preprocessed.csv'\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model (or replace with your training logic)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train = tfidf_vectorizer.fit_transform(train_data['Text'])\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, train_data['Language'])\n",
    "\n",
    "# Monitor model performance over time\n",
    "while True:\n",
    "    # Simulate new data coming in (for testing purposes)\n",
    "    # In a production environment, replace this with actual data fetching logic.\n",
    "    new_data = test_data.sample(frac=0.2, random_state=42)\n",
    "\n",
    "    # Monitor model performance on the new data\n",
    "    accuracy = monitor_model_performance(svm_model, tfidf_vectorizer, new_data)\n",
    "    print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # # Schedule the monitoring every 24 hours\n",
    "    # time.sleep()  # Sleep for 24 hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.67      0.02      0.04       106\n",
      "      Danish       0.94      0.85      0.89        73\n",
      "       Dutch       0.99      0.94      0.96       111\n",
      "     English       0.96      0.98      0.97       291\n",
      "      French       0.98      0.94      0.96       219\n",
      "      German       1.00      0.95      0.97        93\n",
      "       Greek       0.33      0.04      0.08        68\n",
      "       Hindi       0.00      0.00      0.00        10\n",
      "     Italian       0.98      0.90      0.94       145\n",
      "     Kannada       0.33      0.02      0.03        66\n",
      "   Malayalam       0.00      0.00      0.00       121\n",
      "  Portugeese       0.95      0.94      0.94       144\n",
      "     Russian       0.22      0.99      0.35       136\n",
      "     Spanish       0.90      0.94      0.92       160\n",
      "    Sweedish       0.95      0.93      0.94       133\n",
      "       Tamil       0.00      0.00      0.00        87\n",
      "     Turkish       0.99      0.87      0.92       105\n",
      "\n",
      "    accuracy                           0.73      2068\n",
      "   macro avg       0.66      0.61      0.58      2068\n",
      "weighted avg       0.76      0.73      0.70      2068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read the preprocessed data from 'preprocessed.csv'\n",
    "preprocessed_path = 'preprocessed.csv'\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    df['Text'], df['Language'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TF-IDF representation\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(train_data)\n",
    "test_tfidf = tfidf_vectorizer.transform(test_data)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust n_estimators as needed\n",
    "rf_model.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = rf_model.predict(test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "classification_report_result = classification_report(test_labels, predictions)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before hyperparameter tuning: 0.72\n",
      "\n",
      "Classification Report before hyperparameter tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.02      0.04       106\n",
      "      Danish       0.94      0.88      0.91        73\n",
      "       Dutch       1.00      0.93      0.96       111\n",
      "     English       0.97      0.97      0.97       291\n",
      "      French       0.99      0.93      0.96       219\n",
      "      German       0.99      0.92      0.96        93\n",
      "       Greek       0.25      0.01      0.03        68\n",
      "       Hindi       0.00      0.00      0.00        10\n",
      "     Italian       1.00      0.92      0.96       145\n",
      "     Kannada       0.00      0.00      0.00        66\n",
      "   Malayalam       0.00      0.00      0.00       121\n",
      "  Portugeese       0.99      0.92      0.96       144\n",
      "     Russian       0.20      0.99      0.33       136\n",
      "     Spanish       0.97      0.93      0.95       160\n",
      "    Sweedish       0.98      0.88      0.93       133\n",
      "       Tamil       0.00      0.00      0.00        87\n",
      "     Turkish       1.00      0.80      0.89       105\n",
      "\n",
      "    accuracy                           0.72      2068\n",
      "   macro avg       0.66      0.60      0.58      2068\n",
      "weighted avg       0.77      0.72      0.70      2068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KIRANMAI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Read the preprocessed data from 'preprocessed.csv'\n",
    "preprocessed_path = 'preprocessed.csv'\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    df['Text'], df['Language'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TF-IDF representation\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(train_data)\n",
    "test_tfidf = tfidf_vectorizer.transform(test_data)\n",
    "\n",
    "# Initialize and train the Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear', decision_function_shape='ovr')  # 'ovr' for multiclass\n",
    "svm_model.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "model_path = 'multilingual_detection_model.joblib'\n",
    "vectorizer_path = 'tfidf_vectorizer_multilingual.joblib'\n",
    "joblib.dump(svm_model, model_path)\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = svm_model.predict(test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "classification_report_result = classification_report(test_labels, predictions)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"Accuracy before hyperparameter tuning: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report before hyperparameter tuning:\")\n",
    "print(classification_report_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     -------------------------------------- 981.5/981.5 kB 1.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Using legacy 'setup.py install' for langdetect, since package 'wheel' is not installed.\n",
      "Installing collected packages: langdetect\n",
      "  Running setup.py install for langdetect: started\n",
      "  Running setup.py install for langdetect: finished with status 'done'\n",
      "Successfully installed langdetect-1.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(\"this is kiranmai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[te:0.9999999370715171]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_langs(\"ఎలా ఉన్నావ్\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('LanguageDetection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10337 entries, 0 to 10336\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      10337 non-null  object\n",
      " 1   Language  10337 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 161.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['Text']\n",
    "y=df['Language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "for text in X:\n",
    "    text=re.sub(r'[!@#$(),n\"%^*?:;~`0-9]','',text)\n",
    "    text=re.sub(r'[[]]','',text)\n",
    "    text=text.lower()\n",
    "    df_list.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10337, 38665)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10337"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(df_list).toarray()\n",
    "print(X.shape)\n",
    "len(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=41) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ada = LogisticRegression()\n",
    "y_pred=ada.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score ,confusion_matrix\n",
    "ac=f1_score(y_test,y_pred,average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.95\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy={ac:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    x=cv.transform([text]).toarray()\n",
    "    lang=ada.predict(x)\n",
    "    lang=le.inverse_transform(lang)\n",
    "    print('The language is in',lang[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language is in English\n"
     ]
    }
   ],
   "source": [
    "prediction('Hello my name is marshall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language is in French\n"
     ]
    }
   ],
   "source": [
    "prediction('Comment allez-vous ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language is in Hindi\n"
     ]
    }
   ],
   "source": [
    "prediction('आप से मिलकर बहुत ख़ुशी हुई')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langidNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 1.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\kiranmai\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langid) (1.26.2)\n",
      "Using legacy 'setup.py install' for langid, since package 'wheel' is not installed.\n",
      "Installing collected packages: langid\n",
      "  Running setup.py install for langid: started\n",
      "  Running setup.py install for langid: finished with status 'done'\n",
      "Successfully installed langid-1.1.6\n"
     ]
    }
   ],
   "source": [
    "pip install langid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Text DetectedLanguage\n",
      "0      ['nature', 'in', 'the', 'broadest', 'sense', '...               es\n",
      "1      ['nature', 'can', 'refer', 'to', 'the', 'pheno...               en\n",
      "2      ['the', 'study', 'of', 'nature', 'is', 'a', 'l...               en\n",
      "3      ['although', 'humans', 'are', 'part', 'of', 'n...               en\n",
      "4      ['the', 'word', 'nature', 'is', 'borrowed', 'f...               en\n",
      "...                                                  ...              ...\n",
      "10332                                                 []               en\n",
      "10333                                                 []               en\n",
      "10334                                                 []               en\n",
      "10335                                            ['ess']               en\n",
      "10336                                                 []               en\n",
      "\n",
      "[10337 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import langid\n",
    "\n",
    "# Load the preprocessed data (or replace with your data loading logic)\n",
    "preprocessed_path = 'preprocessed.csv'\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "\n",
    "# Assume 'Text' is the column containing the text data\n",
    "texts = df['Text'].tolist()\n",
    "\n",
    "# Detect languages using langid\n",
    "langid_results = [langid.classify(text) for text in texts]\n",
    "\n",
    "# Extract detected languages\n",
    "detected_languages = [lang for lang, _ in langid_results]\n",
    "\n",
    "# Add detected languages to the dataframe\n",
    "df['DetectedLanguage'] = detected_languages\n",
    "\n",
    "# Display the dataframe with detected languages\n",
    "print(df[['Text', 'DetectedLanguage']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
